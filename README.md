# LLM-compressor

Данная работа сделана к качестве итогового проекта курса от Deep Learning School. 

Необходимо было  на базе LLM с помощью алгоритма арифметической компрессии реализовать архиватор текста. Сжать Википедию и посчитать её объём. Улучшить коэффициент компрессии с помощью prefix tuning или steering. Обучить модель генерировать распределение для steering-вектора, чтобы ещё сильнее улучшить компрессию.

Основная часть работы находится в ноутбуках Train Pipeline.ipynb и Metrics.ipynb.

## Подготовка

При подготовке работы были изучены научные статьи [Language Modeling is Compression](https://arxiv.org/pdf/2309.10668), [Variational image compression with a scale hyperprior].
Для сжатия используется датасет Wikipedia [Enwik8](https://www.kaggle.com/datasets/nightfury1103/enwik8).

Запуск моделей производился на Colab с использованием графического процессора T4.


## Без чанков или с чанками

В начале обоснуем необходимость разбиения на чанки при экспериментах. В этом разделе использовалась модель EleutherAI/pythia-70m. Но результаты будут схожими и для других моделей.

Всего сжималось 400 000 бит информации (50 кБ). Весь объем разбивался на части по 16 000 бит (2 кБ). Получается 25 чанков.
Ниже приведена сравнительная таблица результатов сжатия без использования чанков и с разбиением на чанки:

| Метод      | Время кодирования, с | Время декодирования, с | Размер после сжатия, бит | Коэффициент сжатия |
| ---------- | -------------------- | ---------------------- | ------------------------ | ------------------ |
| Без чанков | 733.66               | 731.65                 | 60 471                   | 0.1512             |
| С чанками  | 137.52               | 139.02                 | 66 303                   | 0.1658             |

* Разбиение на чанки даёт почти в 5 × ускорение кодирования и декодирования.
* При этом коэффициент сжатия слегка ухудшается (с 0.1512 до 0.1658), то есть итоговый объём возрастает на \~10 %.
* Так как мы располагаем сравнительно небольшими мощностями, для нас ключевым становится фактор времени. Поэтому все дальнейшие эксперименты мы проводим, использую развиение на чанки.
